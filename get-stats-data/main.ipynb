{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des données de statistiques d'Aftercinema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérification du bon fonctionnement de l'environnement + installations + imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install pandas\n",
    "%pip install sqlalchemy\n",
    "%pip install psycopg2-binary\n",
    "%pip install google-api-python-client\n",
    "%pip install google-auth\n",
    "%pip install google-auth-oauthlib\n",
    "%pip install google-auth-httplib2\n",
    "%pip install apify-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Table, Column, String, MetaData\n",
    "from datetime import datetime,timedelta\n",
    "import xml.etree.ElementTree as ET\n",
    "from sqlalchemy.dialects.postgresql import JSONB\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from apify_client import ApifyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Récupération des données PostHog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.getenv(\"POSTHOG_API_KEY\")\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer \" + token}\n",
    "\n",
    "with open(\"./POSTHOG_QUERIES.json\", 'r') as fichier:\n",
    "    queries = json.load(fichier)\n",
    "\n",
    "events_data = {}\n",
    "\n",
    "for event in [\"Page viewed\",\"Platform button clicked\"]:\n",
    "    data = {\n",
    "        \"query\": {\n",
    "            \"kind\": \"HogQLQuery\",\n",
    "            \"query\": queries[event]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    request = requests.post(\"https://eu.posthog.com/api/projects/20861/query\",headers=headers,json=data)\n",
    "\n",
    "    data = request.json()\n",
    "\n",
    "    df = pd.DataFrame(data[\"results\"])\n",
    "    df.columns = data[\"columns\"]\n",
    "\n",
    "    events_data[event] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traitement des données pour le graphique PostHog - plateformes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms = events_data[\"Platform button clicked\"]\n",
    "\n",
    "df_platforms['platform'] = df_platforms['platform'].replace({'Apple Podcasts': 'apple_podcasts','Apple Podcast': 'apple_podcasts', 'YouTube': 'youtube','Instagram':'instagram','Spotify':'spotify','Deezer':'deezer'})\n",
    "\n",
    "df_platforms = df_platforms.groupby(['platform','person_device']).size().reset_index(name='count')\n",
    "\n",
    "df_platforms.rename(columns={\"person_device\":\"device\"},inplace=True)\n",
    "grouped = df_platforms.groupby('platform').agg({'count': 'sum'}).reset_index()\n",
    "grouped['device'] = 'Tout appareil'\n",
    "df_platforms = pd.concat([df_platforms, grouped], ignore_index=True)\n",
    "\n",
    "platforms = df['platform'].unique()\n",
    "devices = df_platforms['device'].unique()\n",
    "\n",
    "df_platforms_full_index = pd.MultiIndex.from_product([platforms, devices], names=['platform', 'device'])\n",
    "df_platforms_full = pd.DataFrame(index=df_platforms_full_index).reset_index()\n",
    "df_platforms_full = pd.merge(df_platforms_full, df_platforms, on=['platform', 'device'], how='left').fillna(0)\n",
    "\n",
    "posthog_result_platforms = {}\n",
    "for category in devices:\n",
    "    category_df_platforms = df_platforms_full[df_platforms_full['device'] == category]\n",
    "    posthog_result_platforms[category] = [{'platform': row['platform'], 'count': int(row['count'])} for index, row in category_df_platforms.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traitement des données pour le graphique PostHog - pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pages = events_data[\"Page viewed\"]\n",
    "\n",
    "df_pages['time'] = pd.to_datetime(df_pages['time'])\n",
    "df_pages['year_month'] = df_pages['time'].dt.tz_localize(None).dt.to_period('M')\n",
    "\n",
    "df_pages['page'] = df_pages['url'].apply(lambda x: 'listen' if '/listen' in x else ('stats' if '/stats' in x else 'home'))\n",
    "\n",
    "df_pages['device'] = df_pages['person_device'].apply(lambda x: 'Mobile' if x == 'Tablet' else x)\n",
    "df_pages = df_pages.groupby(['year_month', 'page','device']).size().reset_index(name='count')\n",
    "\n",
    "grouped = df_pages.groupby(['year_month','page']).agg({'count': 'sum'}).reset_index()\n",
    "grouped['device'] = 'Tout appareil'\n",
    "df_pages = pd.concat([df_pages, grouped], ignore_index=True)\n",
    "\n",
    "pages = df_pages['page'].unique()\n",
    "devices = df_pages['device'].unique()\n",
    "year_months = df_pages['year_month'].unique()\n",
    "\n",
    "df_pages_full_index = pd.MultiIndex.from_product([pages, devices,year_months], names=['page', 'device','year_month'])\n",
    "df_pages_full = pd.DataFrame(index=df_pages_full_index).reset_index()\n",
    "df_pages_full = pd.merge(df_pages_full, df_pages, on=['page', 'device','year_month'], how='left').fillna(0)\n",
    "\n",
    "posthog_result_pages = {}\n",
    "for category in devices:\n",
    "    category_df_pages = df_pages_full[df_pages_full['device'] == category].copy()\n",
    "    category_df_pages.drop(columns=['device'], inplace=True)\n",
    "    category_df_pages = category_df_pages.pivot(index='year_month', columns='page', values='count').fillna(0).reset_index()\n",
    "    \n",
    "    category_df_pages['home'] = category_df_pages['home'].astype(int)\n",
    "    category_df_pages['listen'] = category_df_pages['listen'].astype(int)\n",
    "    category_df_pages['stats'] = category_df_pages['stats'].astype(int)\n",
    "\n",
    "    month_map = {1: 'jan', 2: 'fév', 3: 'mar', 4: 'avr', 5: 'mai', 6: 'jun',7: 'jui', 8: 'aoû', 9: 'sep', 10: 'oct', 11: 'nov', 12: 'déc'}\n",
    "    category_df_pages['month'] = category_df_pages['year_month'].dt.month.map(month_map) + \" \" + (category_df_pages['year_month'].dt.year % 100).astype(str)\n",
    "    category_df_pages.drop(columns=['year_month'], inplace=True)\n",
    "\n",
    "    category_df_pages = category_df_pages[[\"month\",\"home\",\"listen\",\"stats\"]]\n",
    "\n",
    "    posthog_result_pages[category]=category_df_pages.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Récupération des données Acast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des titres et des ids des épisodes du podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://feeds.acast.com/public/shows/aftercinema\")\n",
    "root = ET.fromstring(response.content)\n",
    "namespaces = {'acast': 'https://schema.acast.com/1.0/'}\n",
    "podcast_episodes = []\n",
    "\n",
    "earliest_date = datetime.max\n",
    "\n",
    "for item in root.findall('.//item'):\n",
    "    episode_id = item.find('acast:episodeId', namespaces).text\n",
    "    title = item.find('title').text\n",
    "    pub_date = item.find('pubDate').text\n",
    "    \n",
    "    if datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %Z') < earliest_date:\n",
    "        earliest_date = datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %Z')\n",
    "\n",
    "    podcast_episodes.append({\n",
    "        \"id\": episode_id,\n",
    "        \"aftercinema_id\":\"A\"+episode_id,\n",
    "        \"title\": title,\n",
    "        \"publishedDate\": datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %Z').strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acast_token = os.getenv(\"ACAST_TOKEN\")\n",
    "headers = {\"Authorization\": \"Bearer \" + acast_token}\n",
    "to_param = datetime.now()-timedelta(days=3)\n",
    "params = {\n",
    "    \"from\": \"2024-02-19T23:00:00.000Z\",\n",
    "    \"to\": to_param,\n",
    "    \"interval\": \"day\",\n",
    "    \"timeZone\": \"Europe/Paris\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des données de téléchargements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://insights-api.acast.com/api/v2/charts/downloads/65d49906c4c0ce0016eadf8c/episode/\"\n",
    "\n",
    "full_df = pd.DataFrame()\n",
    "for episode in podcast_episodes:\n",
    "    response = requests.get(url+episode[\"id\"], params=params,headers=headers)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns={'label': 'date'}, inplace=True)\n",
    "    df['date'] = df['date'].str.split('T').str[0]\n",
    "    df['title'] = episode[\"title\"]\n",
    "    full_df = pd.concat([full_df, df])\n",
    "\n",
    "grouped = full_df.groupby('date').agg({'value': 'sum'}).reset_index()\n",
    "grouped['title'] = 'Tous les épisodes'\n",
    "acast_downloads_df = pd.concat([full_df, grouped], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des données des auditeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://insights-api.acast.com/api/v2/shows/65d49906c4c0ce0016eadf8c/reach/histogram/episode/\"\n",
    "\n",
    "full_df = pd.DataFrame()\n",
    "for episode in podcast_episodes:\n",
    "    response = requests.get(url+episode[\"id\"], params=params,headers=headers)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns={'label': 'date'}, inplace=True)\n",
    "    df['date'] = df['date'].str.split('T').str[0]\n",
    "    df['aftercinema_id'] = episode[\"aftercinema_id\"]\n",
    "    full_df = pd.concat([full_df, df])\n",
    "\n",
    "grouped = full_df.groupby('date').agg({'value': 'sum'}).reset_index()\n",
    "grouped['aftercinema_id'] = 'all_episodes'\n",
    "full_df = pd.concat([full_df, grouped], ignore_index=True)\n",
    "\n",
    "full_df['date'] = pd.to_datetime(full_df['date'])\n",
    "full_df['date_only'] = full_df['date'].dt.date\n",
    "filtered_df = full_df[full_df['date_only'] >= earliest_date.date()]\n",
    "filtered_df = filtered_df.drop(columns=['date_only'])\n",
    "filtered_df['date'] = filtered_df['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "df_pivot = filtered_df.pivot(index='date', columns='aftercinema_id', values='value').reset_index()\n",
    "result_listeners = df_pivot.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des données des plateformes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://insights-api.acast.com/api/v2/shows/65d49906c4c0ce0016eadf8c/clients/histogram?clients=Spotify,Deezer,Apple+Podcasts,Other,Chrome,Safari,Acast+embed-player,Firefox,iVoox,CastBox,Podcast+Addict\"\n",
    "params[\"interval\"] = \"month\"\n",
    "response = requests.get(url, params=params,headers=headers)\n",
    "\n",
    "result_platforms = []\n",
    "autres_total_value = 0\n",
    "specific_platforms = ['Spotify', 'Deezer', 'Apple Podcasts']\n",
    "\n",
    "platforms_codes = {'Apple Podcasts': 'apple_podcasts','Spotify':'spotify','Deezer':'deezer'}\n",
    "\n",
    "for platform in response.json():\n",
    "    platform_name = platform['name']\n",
    "    total_value = sum(item['value'] for item in platform['values'])\n",
    "    \n",
    "    if platform_name in specific_platforms:\n",
    "        result_platforms.append({\"platform\": platforms_codes[platform_name], \"value\": total_value})\n",
    "    else:\n",
    "        autres_total_value += total_value\n",
    "\n",
    "if autres_total_value > 0:\n",
    "    result_platforms.append({\"platform\": \"others\", \"value\": autres_total_value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Récupération des données YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation des requêtes aux APIs YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopes = ['https://www.googleapis.com/auth/yt-analytics.readonly',\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "GOOGLE_AUTH_CLIENT_CONFIG = {\n",
    "  \"installed\":{\n",
    "    \"client_id\":os.getenv(\"GOOGLE_AUTH_CLIENT_ID\"),\n",
    "    \"project_id\":\"aftercinema\",\n",
    "    \"auth_uri\":\"https://accounts.google.com/o/oauth2/auth\",\n",
    "    \"token_uri\":\"https://oauth2.googleapis.com/token\",\n",
    "    \"auth_provider_x509_cert_url\":\"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "    \"client_secret\":os.getenv(\"GOOGLE_AUTH_CLIENT_SECRET\"),\n",
    "    \"redirect_uris\":[\"http://localhost\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "flow = InstalledAppFlow.from_client_config(GOOGLE_AUTH_CLIENT_CONFIG,scopes)\n",
    "credentials = flow.run_local_server()\n",
    "youtubeAnalytics = build(\"youtubeAnalytics\", \"v2\", credentials = credentials)\n",
    "youtube = build('youtube', 'v3', credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des vues par jour et par vidéo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list_response = youtube.playlistItems().list(\n",
    "  part=\"snippet\",\n",
    "  playlistId=\"PLA75TyAwTPpmU0UuoPGXciOMcE9ipNLgT\",\n",
    "  maxResults=50\n",
    ").execute()\n",
    "\n",
    "youtube_views_df = pd.DataFrame()\n",
    "\n",
    "video_list_response_filtered = [\n",
    "    item for item in video_list_response['items']\n",
    "    if item['snippet']['title'] != \"Deleted video\"\n",
    "]\n",
    "\n",
    "for video in video_list_response_filtered:\n",
    "  video_id = video['snippet']['resourceId']['videoId']\n",
    "  stats = youtubeAnalytics.reports().query(\n",
    "    ids='channel==MINE',\n",
    "    startDate='2024-02-19',\n",
    "    endDate='2099-12-31',\n",
    "    metrics='views',\n",
    "    dimensions='day',\n",
    "    sort='day',\n",
    "    filters=f\"video=={video_id}\"\n",
    "  ).execute()\n",
    "  df = pd.DataFrame(stats['rows'], columns=['date', 'value'])\n",
    "  df[\"title\"]=video[\"snippet\"]['title']\n",
    "  youtube_views_df = pd.concat([youtube_views_df,df])\n",
    "\n",
    "grouped = youtube_views_df.groupby('date').agg({'value': 'sum'}).reset_index()\n",
    "grouped['title'] = 'Tous les épisodes'\n",
    "youtube_views_df = pd.concat([youtube_views_df, grouped], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des informations globales YouTube et Acast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_podcast_episodes = {item['title']: item for item in podcast_episodes}\n",
    "general_episodes = []\n",
    "for item1 in video_list_response['items']:\n",
    "    normalized_title = item1['snippet']['title']\n",
    "    if normalized_title in dict_podcast_episodes:\n",
    "        item2 = dict_podcast_episodes[normalized_title]\n",
    "        merged_dict = {\n",
    "            'title': item2['title'],\n",
    "            'acast_id': item2['id'],\n",
    "            'aftercinema_id': item2['aftercinema_id'],\n",
    "            'acast_publishedDate': item2['publishedDate'],\n",
    "            'youtube_id': item1[\"snippet\"]['resourceId']['videoId'],\n",
    "            'youtube_publishedDate': datetime.strptime(item1['snippet']['publishedAt'], \"%Y-%m-%dT%H:%M:%SZ\").strftime('%Y-%m-%dT%H:%M:%S')\n",
    "        }\n",
    "        general_episodes.append(merged_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout des données YouTube aux données Acast (downloads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([youtube_views_df, acast_downloads_df])\n",
    "acast_youtube_downloads = combined_df.groupby(['date', 'title']).agg({'value': 'sum'}).reset_index()\n",
    "\n",
    "df_general_episodes = pd.DataFrame(general_episodes)\n",
    "new_row = pd.DataFrame([{'title': 'Tous les épisodes', 'acast_id': None, 'aftercinema_id': 'all_episodes', 'acast_publishedDate': None, 'youtube_id': None, 'youtube_publishedDate': None}])\n",
    "df_general_episodes = pd.concat([df_general_episodes, new_row], ignore_index=True)\n",
    "\n",
    "df_acast_youtube_downloads = acast_youtube_downloads.merge(df_general_episodes[['title', 'aftercinema_id']], on='title', how='left')\n",
    "df_acast_youtube_downloads = df_acast_youtube_downloads.drop(columns=['title'])\n",
    "\n",
    "df_acast_youtube_downloads['date'] = pd.to_datetime(df_acast_youtube_downloads['date'])\n",
    "df_acast_youtube_downloads['date_only'] = df_acast_youtube_downloads['date'].dt.date\n",
    "df_acast_youtube_downloads_filtered_df = df_acast_youtube_downloads[df_acast_youtube_downloads['date_only'] >= earliest_date.date()]\n",
    "df_acast_youtube_downloads_filtered_df = df_acast_youtube_downloads_filtered_df.drop(columns=['date_only'])\n",
    "df_acast_youtube_downloads_filtered_df['date'] = df_acast_youtube_downloads_filtered_df['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "df_pivot = df_acast_youtube_downloads_filtered_df.pivot(index='date', columns='aftercinema_id', values='value').reset_index()\n",
    "result_downloads = df_pivot.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout des données YouTube aux données Acast (platforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = youtubeAnalytics.reports().query(\n",
    "    ids='channel==MINE',\n",
    "    startDate='2024-02-19',\n",
    "    endDate='2099-12-31',\n",
    "    metrics='views'\n",
    "  ).execute()\n",
    "result_platforms.append({\"platform\": \"youtube\", \"value\": stats[\"rows\"][0][0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des données globale de YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtubeAnalytics = build(\"youtubeAnalytics\", \"v2\", credentials = credentials)\n",
    "stats = youtubeAnalytics.reports().query(\n",
    "    ids='channel==MINE',\n",
    "    startDate='2024-02-19',\n",
    "    endDate='2099-12-31',\n",
    "    metrics='likes,subscribersGained,subscribersLost',\n",
    "  ).execute()\n",
    "youtube_result = {}\n",
    "youtube_result[\"likesCount\"] = stats[\"rows\"][0][0]\n",
    "youtube_result[\"subscribersCount\"] = stats[\"rows\"][0][1]-stats[\"rows\"][0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Récupération des données Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ApifyClient(os.getenv(\"APIFY_TOKEN\"))\n",
    "run = client.actor(\"dSCLg0C3YEZ83HzYX\").call(run_input={ \"usernames\": [\"aftercinema.podcast\"] })\n",
    "apify_result = client.dataset(run[\"defaultDatasetId\"]).list_items().items[0]\n",
    "instagram_result = {}\n",
    "instagram_result[\"followersCount\"] = apify_result[\"followersCount\"]\n",
    "instagram_result[\"postsCount\"] = apify_result[\"postsCount\"]\n",
    "instagram_result[\"likesCount\"] = 0\n",
    "for post in apify_result[\"latestPosts\"]:\n",
    "    instagram_result[\"likesCount\"] = instagram_result[\"likesCount\"] + post[\"likesCount\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stockage du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "def convert_data(data):\n",
    "    return json.dumps(data, ensure_ascii=False)\n",
    "\n",
    "data_to_insert = [\n",
    "    {\n",
    "        \"data_name\":\"PostHog - Page viewed\",\n",
    "        \"data\":posthog_result_pages,\n",
    "        \"date\": date\n",
    "    },\n",
    "    {\n",
    "        \"data_name\":\"PostHog - Platform button clicked\",\n",
    "        \"data\":posthog_result_platforms,\n",
    "        \"date\": date\n",
    "    },\n",
    "    {\n",
    "        \"data_name\":\"Acast+Youtube - Downloads\",\n",
    "        \"data\":result_downloads,\n",
    "        \"date\": date\n",
    "    },\n",
    "    {\n",
    "        \"data_name\":\"Acast - Listeners\",\n",
    "        \"data\":result_listeners,\n",
    "        \"date\": date\n",
    "    },\n",
    "    {\n",
    "        \"data_name\":\"Acast+Youtube - Platforms\",\n",
    "        \"data\":result_platforms,\n",
    "        \"date\": date\n",
    "    },\n",
    "    {\n",
    "        \"data_name\":\"Instagram\",\n",
    "        \"data\":instagram_result,\n",
    "        \"date\": date\n",
    "    },\n",
    "    {\n",
    "        \"data_name\":\"General - Episodes\",\n",
    "        \"data\":sorted(general_episodes, key=lambda x: x['acast_publishedDate']),\n",
    "        \"date\": date\n",
    "    },\n",
    "    {\n",
    "        \"data_name\":\"YouTube\",\n",
    "        \"data\":youtube_result,\n",
    "        \"date\": date\n",
    "    }\n",
    "]\n",
    "\n",
    "engine = create_engine(os.getenv(\"POSTGRESQL_CONN_STRING\"))\n",
    "\n",
    "metadata = MetaData()\n",
    "table = Table('stats_data', metadata,\n",
    "              Column('data_name', String),\n",
    "              Column('data', JSONB),\n",
    "              Column('date', String))\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    with connection.begin() as transaction:\n",
    "        table.drop(engine, checkfirst=True)\n",
    "        transaction.commit()\n",
    "\n",
    "metadata.create_all(engine)\n",
    "for line in data_to_insert:\n",
    "    with engine.connect() as connection:\n",
    "        with connection.begin() as transaction:\n",
    "            connection.execute(table.insert().values(data_name=line[\"data_name\"],data=line[\"data\"],date=line[\"date\"]))\n",
    "            transaction.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
