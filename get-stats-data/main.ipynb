{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des données de statistiques d'Aftercinema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérification du bon fonctionnement de l'environnement + installations + imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install pandas\n",
    "%pip install sqlalchemy\n",
    "%pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Table, Column, String, MetaData\n",
    "from datetime import datetime,timedelta\n",
    "import xml.etree.ElementTree as ET\n",
    "from sqlalchemy.dialects.postgresql import JSONB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Récupération des données PostHog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.getenv(\"POSTHOG_API_KEY\")\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer \" + token}\n",
    "\n",
    "with open(\"./POSTHOG_QUERIES.json\", 'r') as fichier:\n",
    "    queries = json.load(fichier)\n",
    "\n",
    "events_data = {}\n",
    "\n",
    "for event in [\"Page viewed\",\"Platform button clicked\"]:\n",
    "    data = {\n",
    "        \"query\": {\n",
    "            \"kind\": \"HogQLQuery\",\n",
    "            \"query\": queries[event]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    request = requests.post(\"https://eu.posthog.com/api/projects/20861/query\",headers=headers,json=data)\n",
    "\n",
    "    data = request.json()\n",
    "\n",
    "    df = pd.DataFrame(data[\"results\"])\n",
    "    df.columns = data[\"columns\"]\n",
    "\n",
    "    events_data[event] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traitement des données pour le graphique PostHog - plateformes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms = events_data[\"Platform button clicked\"]\n",
    "df_platforms = df_platforms.groupby('platform').size().reset_index(name='count')\n",
    "result_platforms = df_platforms.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traitement des données pour le graphique PostHog - pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pages = events_data[\"Page viewed\"]\n",
    "df_pages['time'] = pd.to_datetime(df_pages['time'])\n",
    "df_pages['year_month'] = df_pages['time'].dt.tz_localize(None).dt.to_period('M')\n",
    "month_map = {1: 'jan', 2: 'fév', 3: 'mar', 4: 'avr', 5: 'mai', 6: 'jun',7: 'jui', 8: 'aoû', 9: 'sep', 10: 'oct', 11: 'nov', 12: 'déc'}\n",
    "df_pages['month'] = df_pages['year_month'].dt.month.map(month_map) + \" \" + (df_pages['year_month'].dt.year % 100).astype(str)\n",
    "df_pages['page'] = df_pages['url'].apply(lambda x: '/listen' if '/listen' in x else '/')\n",
    "df_pages = df_pages.groupby(['month', 'page']).size().reset_index(name='count')\n",
    "df_pages = df_pages.pivot(index='month', columns='page', values='count').fillna(0).reset_index()\n",
    "result_pages = df_pages.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Récupération des données Acast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des titres et des ids des épisodes du podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = requests.get(\"https://feeds.acast.com/public/shows/aftercinema\")\n",
    "root = ET.fromstring(response.content)\n",
    "namespaces = {'acast': 'https://schema.acast.com/1.0/'}\n",
    "podcast_episodes = []\n",
    "\n",
    "for item in root.findall('.//item'):\n",
    "    episode_id = item.find('acast:episodeId', namespaces).text\n",
    "    title = item.find('title').text\n",
    "    pub_date = item.find('pubDate').text\n",
    "    \n",
    "    podcast_episodes.append({\n",
    "        \"id\": episode_id,\n",
    "        \"title\": title,\n",
    "        \"publishedDate\": datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %Z').strftime('%Y-%m-%d')\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acast_token = os.getenv(\"ACAST_TOKEN\")\n",
    "headers = {\"Authorization\": \"Bearer \" + acast_token}\n",
    "to_param = datetime.now()-timedelta(days=1)\n",
    "params = {\n",
    "    \"from\": \"2024-02-19T23:00:00.000Z\",\n",
    "    \"to\": to_param,\n",
    "    \"interval\": \"day\",\n",
    "    \"timeZone\": \"Europe/Paris\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des données de téléchargements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://insights-api.acast.com/api/v2/charts/downloads/65d49906c4c0ce0016eadf8c/episode/\"\n",
    "\n",
    "full_df = pd.DataFrame()\n",
    "for episode in podcast_episodes:\n",
    "    response = requests.get(url+episode[\"id\"], params=params,headers=headers)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns={'label': 'date'}, inplace=True)\n",
    "    df['date'] = df['date'].str.split('T').str[0]\n",
    "    df['title'] = episode[\"title\"]\n",
    "    full_df = pd.concat([full_df, df])\n",
    "\n",
    "grouped = full_df.groupby('date').agg({'value': 'sum'}).reset_index()\n",
    "grouped['title'] = 'Tous les épisodes'\n",
    "full_df = pd.concat([full_df, grouped], ignore_index=True)\n",
    "\n",
    "df_pivot = full_df.pivot(index='date', columns='title', values='value').reset_index()\n",
    "result_downloads = df_pivot.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des données des auditeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://insights-api.acast.com/api/v2/shows/65d49906c4c0ce0016eadf8c/reach/histogram/episode/\"\n",
    "\n",
    "full_df = pd.DataFrame()\n",
    "for episode in podcast_episodes:\n",
    "    response = requests.get(url+episode[\"id\"], params=params,headers=headers)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns={'label': 'date'}, inplace=True)\n",
    "    df['date'] = df['date'].str.split('T').str[0]\n",
    "    df['title'] = episode[\"title\"]\n",
    "    full_df = pd.concat([full_df, df])\n",
    "\n",
    "grouped = full_df.groupby('date').agg({'value': 'sum'}).reset_index()\n",
    "grouped['title'] = 'Tous les épisodes'\n",
    "full_df = pd.concat([full_df, grouped], ignore_index=True)\n",
    "\n",
    "df_pivot = full_df.pivot(index='date', columns='title', values='value').reset_index()\n",
    "result_listeners = df_pivot.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des données des plateformes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://insights-api.acast.com/api/v2/shows/65d49906c4c0ce0016eadf8c/clients/histogram?clients=Spotify,Deezer,Apple+Podcasts,Other,Chrome,Safari,Acast+embed-player,Firefox,iVoox,CastBox,Podcast+Addict\"\n",
    "platform_params = params\n",
    "platform_params[\"interval\"] = \"month\"\n",
    "response = requests.get(url, params=platform_params,headers=headers)\n",
    "\n",
    "result_platforms = []\n",
    "autres_total_value = 0\n",
    "specific_platforms = ['Spotify', 'Deezer', 'Apple Podcasts']\n",
    "\n",
    "for platform in response.json():\n",
    "    platform_name = platform['name']\n",
    "    total_value = sum(item['value'] for item in platform['values'])\n",
    "    \n",
    "    if platform_name in specific_platforms:\n",
    "        result_platforms.append({\"platform\": platform_name, \"value\": total_value})\n",
    "    else:\n",
    "        autres_total_value += total_value\n",
    "\n",
    "if autres_total_value > 0:\n",
    "    result_platforms.append({\"platform\": \"autres\", \"value\": autres_total_value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Récupération des données YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-api-python-client\n",
    "%pip install google-auth\n",
    "%pip install google-auth-oauthlib\n",
    "%pip install google-auth-httplib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.oauth2.credentials\n",
    "import google_auth_oauthlib.flow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/yt-analytics.readonly']\n",
    "\n",
    "API_SERVICE_NAME = 'youtubeAnalytics'\n",
    "API_VERSION = 'v2'\n",
    "CLIENT_SECRETS_FILE = 'YOUR_CLIENT_SECRET_FILE.json'\n",
    "def get_service():\n",
    "  flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRETS_FILE, SCOPES)\n",
    "  credentials = flow.run_local_server()\n",
    "  return build(API_SERVICE_NAME, API_VERSION, credentials = credentials)\n",
    "\n",
    "def execute_api_request(client_library_function, **kwargs):\n",
    "  response = client_library_function(\n",
    "    **kwargs\n",
    "  ).execute()\n",
    "\n",
    "  print(response)\n",
    "%env OAUTHLIB_INSECURE_TRANSPORT=1\n",
    "if __name__ == '__main__':\n",
    "  # Disable OAuthlib's HTTPs verification when running locally.\n",
    "  # *DO NOT* leave this option enabled when running in production.\n",
    "  os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n",
    "\n",
    "  youtubeAnalytics = get_service()\n",
    "  execute_api_request(\n",
    "      youtubeAnalytics.reports().query,\n",
    "      ids='channel==MINE',\n",
    "      startDate='2024-01-01',\n",
    "      endDate='2024-12-31',\n",
    "      metrics='views',\n",
    "      dimensions='day',\n",
    "      sort='day'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Créer des informations d'identification pour le compte de service\n",
    "credentials = service_account.Credentials.from_service_account_info(\n",
    "    SERVICE_ACCOUNT_INFO,\n",
    "    scopes=[\"https://www.googleapis.com/auth/youtube.readonly\",\n",
    "            \"https://www.googleapis.com/auth/yt-analytics.readonly\"]\n",
    ")\n",
    "\n",
    "# Construire le client YouTube API\n",
    "youtube = build('youtube', 'v3', credentials=credentials)\n",
    "youtube_analytics = build('youtubeAnalytics', 'v2', credentials=credentials)\n",
    "\n",
    "request = youtube.playlistItems().list(\n",
    "        part=\"snippet\",\n",
    "        playlistId=\"PLA75TyAwTPpmU0UuoPGXciOMcE9ipNLgT\",\n",
    "        maxResults=50\n",
    "    ).execute()\n",
    "request\n",
    "# def get_video_views(video_id):\n",
    "#     request = youtube_analytics.reports().query(\n",
    "#         ids=\"channel==MINE\",\n",
    "#         startDate='2024-01-01',\n",
    "#         endDate='2024-12-31',\n",
    "#         metrics=\"views\",\n",
    "#         dimensions=\"day\",\n",
    "#         filters=f\"video=={video_id}\"\n",
    "#     )\n",
    "#     response = request.execute()\n",
    "#     return response\n",
    "\n",
    "# for video in request['items']:\n",
    "#     stats = get_video_views(video['snippet']['resourceId']['videoId'])\n",
    "#     print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = youtube_analytics.reports().query(\n",
    "        ids=\"channel==UCqyW0dbyHKY0i1H88128AFg\",\n",
    "        startDate='2024-01-01',\n",
    "        endDate='2024-08-01',\n",
    "        metrics=\"views\",\n",
    "        dimensions=\"day\",\n",
    "        sort=\"day\"\n",
    "    )\n",
    "response = request.execute()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stockage du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "def convert_data(data):\n",
    "    return json.dumps(data, ensure_ascii=False)\n",
    "\n",
    "data_to_insert = [\n",
    "    {\n",
    "        \"data_name\":\"PostHog - Page viewed\",\n",
    "        \"data\":result_pages,\n",
    "        \"date\": date\n",
    "    },\n",
    "    {\n",
    "        \"data_name\":\"PostHog - Platform button clicked\",\n",
    "        \"data\":result_platforms,\n",
    "        \"date\": date\n",
    "    },\n",
    "    {\n",
    "        \"data_name\":\"Acast - Downloads\",\n",
    "        \"data\":result_downloads,\n",
    "        \"date\": date\n",
    "    },\n",
    "    {\n",
    "        \"data_name\":\"Acast - Listeners\",\n",
    "        \"data\":result_listeners,\n",
    "        \"date\": date\n",
    "    },\n",
    "    {\n",
    "        \"data_name\":\"Acast - Platforms\",\n",
    "        \"data\":result_platforms,\n",
    "        \"date\": date\n",
    "    }\n",
    "]\n",
    "\n",
    "engine = create_engine(os.getenv(\"POSTGRESQL_CONN_STRING\"))\n",
    "\n",
    "metadata = MetaData()\n",
    "table = Table('stats_data', metadata,\n",
    "              Column('data_name', String),\n",
    "              Column('data', JSONB),\n",
    "              Column('date', String))\n",
    "\n",
    "metadata.create_all(engine)\n",
    "\n",
    "for line in data_to_insert:\n",
    "    with engine.connect() as connection:\n",
    "        with connection.begin() as transaction:\n",
    "            connection.execute(table.insert().values(data_name=line[\"data_name\"],data=line[\"data\"],date=line[\"date\"]))\n",
    "            transaction.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
